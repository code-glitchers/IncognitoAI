# ğŸ§ IncognitoAI Linux Setup - COMPLETE âœ…

## ğŸ“¦ What Was Created

A complete Linux setup folder with **TWO interfaces** for IncognitoAI:

### Folder Structure
```
linux/
â”œâ”€â”€ ğŸ“„ README.md                   â† Full documentation
â”œâ”€â”€ ğŸ”§ setup.sh                    â† Automated setup script
â”œâ”€â”€ â–¶ï¸  start.sh                    â† Launch Streamlit version
â”œâ”€â”€ â–¶ï¸  bot.sh                      â† Launch Flask Cyberpunk version
â”œâ”€â”€ ğŸ bot.py                      â† Flask application with AI
â”œâ”€â”€ ğŸ“ templates/
â”‚   â””â”€â”€ bot.html                   â† Web interface
â””â”€â”€ ğŸ“ static/
    â”œâ”€â”€ bot.css                    â† Cyberpunk styling
    â””â”€â”€ bot.js                     â† Interactive features
```

---

## ğŸ¯ TWO INTERFACES AVAILABLE

### 1ï¸âƒ£ **STREAMLIT VERSION** (Original)
- **Command:** `./start.sh`
- **Port:** `http://localhost:8501`
- **Features:** Simple, clean interface
- **Best for:** Quick testing

### 2ï¸âƒ£ **FLASK CYBERPUNK VERSION** (New!) âœ¨
- **Command:** `./bot.sh`
- **Port:** `http://localhost:5000`
- **Features:**
  - ğŸŒ Beautiful neon cyberpunk aesthetic
  - ğŸ’¬ Real-time chat interface
  - ğŸ“ Document upload with RAG
  - ğŸ”„ RAG mode toggle
  - ğŸŸ¢ System status indicator
  - ğŸ“± Responsive design

**Recommended:** Use Flask Cyberpunk version for best experience!

---

## ğŸš€ QUICK START (3 Steps)

### Step 1: Initial Setup (ONE TIME)
```bash
cd linux
chmod +x setup.sh start.sh bot.sh
./setup.sh
```

This will:
- âœ… Install Python 3 (if needed)
- âœ… Create virtual environment
- âœ… Install dependencies
- âœ… Install Ollama (if needed)
- âœ… Download AI models (5-10 minutes)

### Step 2: Start Ollama (New Terminal)
```bash
ollama serve
```

### Step 3: Launch IncognitoAI (New Terminal)
```bash
cd linux
./bot.sh         # Flask Cyberpunk (recommended!)
# OR
./start.sh       # Streamlit version
```

---

## ğŸ¨ Flask Cyberpunk Features

### Interface Design
- **Dark Theme:** Cyberpunk aesthetic with neon accents
- **Neon Colors:** Pink, cyan, purple, green glows
- **Responsive:** Works on desktop and mobile
- **Animations:** Smooth transitions and effects

### Functionality
- ğŸ’¬ **Real-time Chat:** Type and get instant responses
- ğŸ“ **Upload Documents:** PDF, TXT, Markdown support
- ğŸ§  **RAG Mode:** Chat with your documents
- ğŸ” **Status Monitor:** See if Ollama is running
- ğŸ“Š **System Info:** Model details and features

### User Experience
- Auto-focus on input field
- Enter to send, Shift+Enter for newline
- Typing indicator while waiting for response
- Scroll to latest message
- Clean message history

---

## ğŸ“‹ FILES EXPLAINED

| File | Purpose |
|------|---------|
| `setup.sh` | Automated Linux setup - installs everything |
| `start.sh` | Launches Streamlit interface (app.py) |
| `bot.sh` | Launches Flask Cyberpunk interface (bot.py) |
| `bot.py` | Flask app with AI logic and web routes |
| `bot.html` | Web page HTML structure |
| `bot.css` | Neon cyberpunk styling |
| `bot.js` | Interactive chat functionality |
| `README.md` | Complete documentation |

---

## ğŸ”§ REQUIREMENTS

### System Requirements
- **OS:** Linux or macOS (Ubuntu 20.04+, Debian, Fedora, macOS 10.14+, etc.)
- **Python:** 3.8 or higher
- **RAM:** 4GB minimum (8GB recommended)
- **Disk:** 2GB+ free space
- **Internet:** For initial setup only

### Auto-Installed by Setup Script
- Python packages (Flask, LangChain, ChromaDB, Streamlit, etc.)
- Ollama (AI runtime)
- AI models (llama3.2:1b, all-minilm)

---

## ğŸŒŸ KEY FEATURES

### IncognitoAI Linux Setup
âœ… **One-click setup** - Fully automated  
âœ… **Two interfaces** - Streamlit + Flask Cyberpunk  
âœ… **Beautiful design** - Modern cyberpunk aesthetic  
âœ… **Fast performance** - Optimized for Linux/macOS  
âœ… **RAG support** - Chat with documents  
âœ… **100% offline** - No data leaves your machine  
âœ… **Easy to use** - Simple shell scripts  
âœ… **Well documented** - Multiple guides included  

---

## âš™ï¸ HOW IT WORKS

### Architecture
```
Your Computer (Linux/macOS)
    â†“
Ollama (AI Engine) - Port 11434
    â†“
Flask App (Web Interface) - Port 5000
    â†“
Browser (http://localhost:5000)
```

### Data Flow
1. **User Input** â†’ Web browser sends message
2. **Processing** â†’ Flask app prepares query
3. **AI Response** â†’ Ollama generates response
4. **Display** â†’ Flask sends response to browser
5. **ALL LOCAL** â†’ Nothing leaves your computer

---

## ğŸ“ USAGE EXAMPLES

### Basic Chat
1. Open http://localhost:5000
2. Type your question
3. Press Enter
4. Get instant response

### RAG Mode (Chat with Documents)
1. Click ğŸ“ button
2. Select PDF/TXT/Markdown file
3. Upload completes automatically
4. Enable "RAG" toggle
5. Ask questions about your document

### Models
- **llama3.2:1b** - Fast, efficient AI model
- **all-minilm** - Embedding model for document search

---

## ğŸ› TROUBLESHOOTING

### Setup Issues

**Q: "ollama: command not found"**
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

**Q: "Python not found"**
```bash
# Ubuntu/Debian
sudo apt-get update
sudo apt-get install python3 python3-pip

# macOS
brew install python@3.11
```

**Q: "Permission denied on script"**
```bash
chmod +x setup.sh start.sh bot.sh
```

### Runtime Issues

**Q: "Connection refused" on port 5000**
```bash
# Port already in use - edit bot.py:
# Find: app.run(debug=True, host='0.0.0.0', port=5000)
# Change to: app.run(debug=True, host='0.0.0.0', port=5001)
```

**Q: "Ollama offline" warning**
- Make sure to run `ollama serve` in another terminal

**Q: "Models not loading"**
```bash
ollama pull llama3.2:1b
ollama pull all-minilm
```

---

## ğŸ”’ PRIVACY & SECURITY

âœ… **100% Offline** - No data sent anywhere  
âœ… **No Tracking** - Zero telemetry  
âœ… **No Ads** - Clean interface  
âœ… **Open Source** - MIT License  
âœ… **Your Data** - Stored only on your machine  
âœ… **No Account** - No login required  

---

## ğŸ“š DOCUMENTATION

- **[README.md](README.md)** - Complete Linux/macOS setup guide
- **[../README.md](../README.md)** - Main project documentation
- **Ollama:** https://ollama.ai
- **Flask:** https://flask.palletsprojects.com
- **Streamlit:** https://streamlit.io

---

## ğŸ’¡ TIPS & TRICKS

1. **Use both interfaces** - Try Streamlit and Cyberpunk
2. **Upload documents** - Test RAG with your PDFs
3. **Clear database** - Delete `.chroma_db` folder to reset
4. **Customize theme** - Edit `static/bot.css`
5. **Different models** - Change `MODEL_NAME` in `bot.py`

---

## ğŸ“ LEARNING PATH

1. Run setup script: `./setup.sh`
2. Read documentation: `README.md`
3. Try Flask Cyberpunk: `./bot.sh`
4. Upload a test document
5. Explore RAG mode
6. Customize and extend

---

## ğŸ“ SUPPORT

Having issues? Check:
1. README.md - Detailed setup guide
2. ../README.md - Main documentation
3. Terminal error messages - Usually very helpful
4. GitHub Issues - Open an issue if stuck

---

## ğŸ‰ YOU'RE ALL SET!

Your Linux/macOS IncognitoAI setup is complete and ready to use.

### Next Steps:
1. Run `./setup.sh` in the linux folder
2. Start Ollama in another terminal: `ollama serve`
3. Launch the Cyberpunk interface: `./bot.sh`
4. Open http://localhost:5000
5. Start chatting!

**Enjoy your private, offline AI assistant!** ğŸŒâœ¨

---

*IncognitoAI - Made with â¤ï¸ for privacy-conscious users*
*MIT License - Open Source*
